{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'tarfile_extractall' from 'sklearn.utils.fixes' (c:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resample\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomUnderSampler\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline \u001b[38;5;28;01mas\u001b[39;00m ImbPipeline\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\base.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m METHODS\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sklearn_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fit_context, get_tags, validate_data\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\utils\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`imblearn.utils` module includes various utilities.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Substitution\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     check_neighbors_object,\n\u001b[0;32m      8\u001b[0m     check_sampling_strategy,\n\u001b[0;32m      9\u001b[0m     check_target_type,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_neighbors_object\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_sampling_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_target_type\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubstitution\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\utils\\_validation.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m type_of_target\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _num_samples\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sklearn_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_pandas_df, check_array\n\u001b[0;32m     22\u001b[0m SAMPLING_KIND \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mover-sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder-sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbypass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m TARGET_KIND \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\utils\\_sklearn_compat.py:370\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;66;03m########################################################################################\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# Upgrading for scikit-learn 1.6\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;66;03m########################################################################################\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sklearn_version \u001b[38;5;241m<\u001b[39m parse_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.6\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;66;03m# test_common\u001b[39;00m\n\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator_checks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _construct_instance\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtype_of_target\u001b[39m(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m, raise_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    373\u001b[0m         \u001b[38;5;66;03m# fix for raise_unknown which is introduced in scikit-learn 1.6\u001b[39;00m\n\u001b[0;32m    374\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m type_of_target\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\estimator_checks.py:45\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m     ClusterMixin,\n\u001b[0;32m     40\u001b[0m     clone,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     is_regressor,\n\u001b[0;32m     44\u001b[0m )\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     46\u001b[0m     load_iris,\n\u001b[0;32m     47\u001b[0m     make_blobs,\n\u001b[0;32m     48\u001b[0m     make_classification,\n\u001b[0;32m     49\u001b[0m     make_multilabel_classification,\n\u001b[0;32m     50\u001b[0m     make_regression,\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m     DataConversionWarning,\n\u001b[0;32m     54\u001b[0m     EstimatorCheckFailedWarning,\n\u001b[0;32m     55\u001b[0m     NotFittedError,\n\u001b[0;32m     56\u001b[0m     SkipTestWarning,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearClassifierMixin\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\datasets\\__init__.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_covtype\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_covtype\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kddcup99\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_kddcup99\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lfw\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_lfw_pairs, fetch_lfw_people\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_olivetti_faces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_olivetti_faces\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_openml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_openml\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\datasets\\_lfw.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hidden, Interval, StrOptions, validate_params\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tarfile_extractall\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     RemoteFileMetadata,\n\u001b[0;32m     25\u001b[0m     _fetch_remote,\n\u001b[0;32m     26\u001b[0m     get_data_home,\n\u001b[0;32m     27\u001b[0m     load_descr,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'tarfile_extractall' from 'sklearn.utils.fixes' (c:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"asthma_detection.csv\")\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Class distribution:\\n{df['Asthma'].value_counts()}\")\n",
    "\n",
    "# 1. ADVANCED DATA PREPROCESSING\n",
    "\n",
    "def advanced_outlier_removal(df, method='iqr', factor=1.5):\n",
    "    \"\"\"Remove outliers using IQR or Z-score method\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    numeric_cols = [col for col in numeric_cols if col != 'Asthma']\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if method == 'iqr':\n",
    "            Q1 = df_clean[col].quantile(0.25)\n",
    "            Q3 = df_clean[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - factor * IQR\n",
    "            upper_bound = Q3 + factor * IQR\n",
    "            df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "        elif method == 'zscore':\n",
    "            z_scores = np.abs((df_clean[col] - df_clean[col].mean()) / df_clean[col].std())\n",
    "            df_clean = df_clean[z_scores < factor]\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def create_feature_interactions(df):\n",
    "    \"\"\"Create meaningful feature interactions\"\"\"\n",
    "    df_enhanced = df.copy()\n",
    "    \n",
    "    # Respiratory symptoms interaction\n",
    "    df_enhanced['Respiratory_Score'] = (df_enhanced['Dry-Cough'] + \n",
    "                                       df_enhanced['Difficulty-in-Breathing'] + \n",
    "                                       df_enhanced['Sore-Throat']) / 3\n",
    "    \n",
    "    # Nasal symptoms interaction\n",
    "    df_enhanced['Nasal_Score'] = (df_enhanced['Nasal-Congestion'] + \n",
    "                                 df_enhanced['Runny-Nose']) / 2\n",
    "    \n",
    "    # Overall symptom severity\n",
    "    symptom_cols = ['Tiredness', 'Dry-Cough', 'Difficulty-in-Breathing', \n",
    "                   'Sore-Throat', 'Pains', 'Nasal-Congestion', 'Runny-Nose']\n",
    "    df_enhanced['Total_Symptom_Score'] = df_enhanced[symptom_cols].sum(axis=1)\n",
    "    df_enhanced['Avg_Symptom_Score'] = df_enhanced[symptom_cols].mean(axis=1)\n",
    "    \n",
    "    # Age-related features\n",
    "    if 'Age_60+' in df_enhanced.columns:\n",
    "        df_enhanced['Age_Symptom_Interaction'] = df_enhanced['Age_60+'] * df_enhanced['Total_Symptom_Score']\n",
    "    \n",
    "    # Symptom combinations\n",
    "    df_enhanced['Cough_Breathing_Combo'] = df_enhanced['Dry-Cough'] * df_enhanced['Difficulty-in-Breathing']\n",
    "    df_enhanced['Nasal_Throat_Combo'] = df_enhanced['Nasal-Congestion'] * df_enhanced['Sore-Throat']\n",
    "    \n",
    "    return df_enhanced\n",
    "\n",
    "# Apply advanced preprocessing\n",
    "df_clean = advanced_outlier_removal(df, method='iqr', factor=1.5)\n",
    "df_enhanced = create_feature_interactions(df_clean)\n",
    "\n",
    "print(f\"After outlier removal: {df_clean.shape}\")\n",
    "print(f\"After feature engineering: {df_enhanced.shape}\")\n",
    "\n",
    "# 2. FEATURE SELECTION AND SCALING\n",
    "\n",
    "def select_best_features(X, y, k=15):\n",
    "    \"\"\"Select k best features using statistical tests\"\"\"\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "    return X_selected, selected_features, selector\n",
    "\n",
    "# Prepare features and target\n",
    "X = df_enhanced.drop('Asthma', axis=1)\n",
    "y = df_enhanced['Asthma']\n",
    "\n",
    "# Feature selection\n",
    "X_selected, selected_features, feature_selector = select_best_features(X, y, k=min(15, X.shape[1]))\n",
    "print(f\"Selected features: {list(selected_features)}\")\n",
    "\n",
    "# 3. HANDLE CLASS IMBALANCE\n",
    "print(f\"Class distribution before balancing:\\n{pd.Series(y).value_counts()}\")\n",
    "\n",
    "# Apply SMOTE for oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X_selected, y)\n",
    "print(f\"Class distribution after SMOTE:\\n{pd.Series(y_balanced).value_counts()}\")\n",
    "\n",
    "# 4. TRAIN-TEST SPLIT WITH STRATIFICATION\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced\n",
    ")\n",
    "\n",
    "# 5. SCALING\n",
    "scaler = RobustScaler()  # More robust to outliers than StandardScaler\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. HYPERPARAMETER TUNING\n",
    "\n",
    "def tune_random_forest(X_train, y_train):\n",
    "    \"\"\"Tune Random Forest hyperparameters\"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def tune_gradient_boosting(X_train, y_train):\n",
    "    \"\"\"Tune Gradient Boosting hyperparameters\"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "    \n",
    "    gb = GradientBoostingClassifier(random_state=42)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(gb, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def tune_svm(X_train, y_train):\n",
    "    \"\"\"Tune SVM hyperparameters\"\"\"\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
    "        'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "    }\n",
    "    \n",
    "    svm = SVC(random_state=42)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "print(\"Tuning Random Forest...\")\n",
    "best_rf, best_rf_params = tune_random_forest(X_train_scaled, y_train)\n",
    "print(f\"Best RF params: {best_rf_params}\")\n",
    "\n",
    "print(\"Tuning Gradient Boosting...\")\n",
    "best_gb, best_gb_params = tune_gradient_boosting(X_train_scaled, y_train)\n",
    "print(f\"Best GB params: {best_gb_params}\")\n",
    "\n",
    "print(\"Tuning SVM...\")\n",
    "best_svm, best_svm_params = tune_svm(X_train_scaled, y_train)\n",
    "print(f\"Best SVM params: {best_svm_params}\")\n",
    "\n",
    "# 7. ENSEMBLE METHODS\n",
    "\n",
    "# Create individual models\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Create voting classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', best_rf),\n",
    "        ('gb', best_gb),\n",
    "        ('svm', best_svm),\n",
    "        ('lr', lr)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 8. MODEL EVALUATION\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1, y_pred\n",
    "\n",
    "# Evaluate all models\n",
    "models = {\n",
    "    'Tuned Random Forest': best_rf,\n",
    "    'Tuned Gradient Boosting': best_gb,\n",
    "    'Tuned SVM': best_svm,\n",
    "    'Logistic Regression': lr,\n",
    "    'Voting Ensemble': voting_clf\n",
    "}\n",
    "\n",
    "results = {}\n",
    "predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    acc, prec, rec, f1, y_pred = evaluate_model(model, X_test_scaled, y_test, name)\n",
    "    results[name] = {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1}\n",
    "    predictions[name] = y_pred\n",
    "\n",
    "# 9. CROSS-VALIDATION FOR BEST MODEL\n",
    "best_model_name = max(results.items(), key=lambda x: x[1]['accuracy'])[0]\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name}\")\n",
    "print(\"Performing cross-validation...\")\n",
    "\n",
    "cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"CV Accuracy: {cv_scores.mean():.4f} (±{cv_scores.std()*2:.4f})\")\n",
    "\n",
    "# 10. FEATURE IMPORTANCE\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': selected_features,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_importance.head(10), x='importance', y='feature')\n",
    "    plt.title(f'Top 10 Feature Importances - {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "\n",
    "# 11. CONFUSION MATRIX FOR BEST MODEL\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, predictions[best_model_name])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=np.unique(y_test),\n",
    "            yticklabels=np.unique(y_test))\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# 12. MODEL COMPARISON VISUALIZATION\n",
    "results_df = pd.DataFrame(results).T\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i//2, i%2]\n",
    "    results_df[metric].plot(kind='bar', ax=ax, color='skyblue')\n",
    "    ax.set_title(f'Model Comparison - {metric.capitalize()}')\n",
    "    ax.set_ylabel(metric.capitalize())\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 13. SAVE THE BEST MODEL\n",
    "from joblib import dump\n",
    "dump(best_model, f'best_asthma_model_{best_model_name.lower().replace(\" \", \"_\")}.pkl')\n",
    "dump(scaler, 'asthma_scaler.pkl')\n",
    "dump(feature_selector, 'asthma_feature_selector.pkl')\n",
    "\n",
    "print(f\"\\nBest model saved as: best_asthma_model_{best_model_name.lower().replace(' ', '_')}.pkl\")\n",
    "print(\"Scaler and feature selector also saved.\")\n",
    "\n",
    "# 14. PREDICTION FUNCTION\n",
    "def predict_asthma(symptoms_dict, model=best_model, scaler=scaler, selector=feature_selector):\n",
    "    \"\"\"\n",
    "    Predict asthma level for new symptoms\n",
    "    \n",
    "    symptoms_dict should contain all original features\n",
    "    \"\"\"\n",
    "    # Create DataFrame from input\n",
    "    input_df = pd.DataFrame([symptoms_dict])\n",
    "    \n",
    "    # Apply same feature engineering\n",
    "    input_enhanced = create_feature_interactions(input_df)\n",
    "    \n",
    "    # Select features\n",
    "    input_selected = selector.transform(input_enhanced)\n",
    "    \n",
    "    # Scale features\n",
    "    input_scaled = scaler.transform(input_selected)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(input_scaled)[0]\n",
    "    probability = model.predict_proba(input_scaled)[0] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    return prediction, probability\n",
    "\n",
    "# Example usage\n",
    "example_symptoms = {\n",
    "    'Age_60+': 0,\n",
    "    'Tiredness': 3,\n",
    "    'Dry-Cough': 4,\n",
    "    'Difficulty-in-Breathing': 5,\n",
    "    'Sore-Throat': 2,\n",
    "    'Pains': 1,\n",
    "    'Nasal-Congestion': 3,\n",
    "    'Runny-Nose': 2\n",
    "}\n",
    "\n",
    "prediction, probability = predict_asthma(example_symptoms)\n",
    "print(f\"\\nExample prediction: {prediction}\")\n",
    "if probability is not None:\n",
    "    print(f\"Prediction probabilities: {probability}\")\n",
    "\n",
    "print(f\"\\nFinal Accuracy Improvement:\")\n",
    "print(f\"Original Accuracy: 84%\")\n",
    "print(f\"Best Model Accuracy: {results[best_model_name]['accuracy']*100:.2f}%\")\n",
    "print(f\"Improvement: {(results[best_model_name]['accuracy'] - 0.84)*100:.2f} percentage points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'tarfile_extractall' from 'sklearn.utils.fixes' (c:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n",
      "\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
      "\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resample\n",
      "\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n",
      "\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomUnderSampler\n",
      "\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline \u001b[38;5;28;01mas\u001b[39;00m ImbPipeline\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n",
      "\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n",
      "\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n",
      "\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[0;32m     53\u001b[0m         combine,\n",
      "\u001b[0;32m     54\u001b[0m         ensemble,\n",
      "\u001b[0;32m     55\u001b[0m         exceptions,\n",
      "\u001b[0;32m     56\u001b[0m         metrics,\n",
      "\u001b[0;32m     57\u001b[0m         over_sampling,\n",
      "\u001b[0;32m     58\u001b[0m         pipeline,\n",
      "\u001b[0;32m     59\u001b[0m         tensorflow,\n",
      "\u001b[0;32m     60\u001b[0m         under_sampling,\n",
      "\u001b[0;32m     61\u001b[0m         utils,\n",
      "\u001b[0;32m     62\u001b[0m     )\n",
      "\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n",
      "\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n",
      "\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n",
      "\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n",
      "\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n",
      "\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n",
      "\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n",
      "\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n",
      "\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n",
      "\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\base.py:15\u001b[0m\n",
      "\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m METHODS\n",
      "\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n",
      "\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n",
      "\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sklearn_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fit_context, get_tags, validate_data\n",
      "\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\utils\\__init__.py:6\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`imblearn.utils` module includes various utilities.\u001b[39;00m\n",
      "\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Substitution\n",
      "\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[0;32m      7\u001b[0m     check_neighbors_object,\n",
      "\u001b[0;32m      8\u001b[0m     check_sampling_strategy,\n",
      "\u001b[0;32m      9\u001b[0m     check_target_type,\n",
      "\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n",
      "\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_neighbors_object\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_sampling_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_target_type\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubstitution\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m     17\u001b[0m ]\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\utils\\_validation.py:20\u001b[0m\n",
      "\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m type_of_target\n",
      "\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _num_samples\n",
      "\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sklearn_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_pandas_df, check_array\n",
      "\u001b[0;32m     22\u001b[0m SAMPLING_KIND \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mover-sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder-sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbypass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m     28\u001b[0m )\n",
      "\u001b[0;32m     29\u001b[0m TARGET_KIND \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\utils\\_sklearn_compat.py:370\u001b[0m\n",
      "\u001b[0;32m    363\u001b[0m \u001b[38;5;66;03m########################################################################################\u001b[39;00m\n",
      "\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# Upgrading for scikit-learn 1.6\u001b[39;00m\n",
      "\u001b[0;32m    365\u001b[0m \u001b[38;5;66;03m########################################################################################\u001b[39;00m\n",
      "\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sklearn_version \u001b[38;5;241m<\u001b[39m parse_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.6\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;32m    369\u001b[0m     \u001b[38;5;66;03m# test_common\u001b[39;00m\n",
      "\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator_checks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _construct_instance\n",
      "\u001b[0;32m    372\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtype_of_target\u001b[39m(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m, raise_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[0;32m    373\u001b[0m         \u001b[38;5;66;03m# fix for raise_unknown which is introduced in scikit-learn 1.6\u001b[39;00m\n",
      "\u001b[0;32m    374\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m type_of_target\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\estimator_checks.py:45\u001b[0m\n",
      "\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context\n",
      "\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[0;32m     39\u001b[0m     ClusterMixin,\n",
      "\u001b[0;32m     40\u001b[0m     clone,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     43\u001b[0m     is_regressor,\n",
      "\u001b[0;32m     44\u001b[0m )\n",
      "\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[0;32m     46\u001b[0m     load_iris,\n",
      "\u001b[0;32m     47\u001b[0m     make_blobs,\n",
      "\u001b[0;32m     48\u001b[0m     make_classification,\n",
      "\u001b[0;32m     49\u001b[0m     make_multilabel_classification,\n",
      "\u001b[0;32m     50\u001b[0m     make_regression,\n",
      "\u001b[0;32m     51\u001b[0m )\n",
      "\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[0;32m     53\u001b[0m     DataConversionWarning,\n",
      "\u001b[0;32m     54\u001b[0m     EstimatorCheckFailedWarning,\n",
      "\u001b[0;32m     55\u001b[0m     NotFittedError,\n",
      "\u001b[0;32m     56\u001b[0m     SkipTestWarning,\n",
      "\u001b[0;32m     57\u001b[0m )\n",
      "\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearClassifierMixin\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\datasets\\__init__.py:25\u001b[0m\n",
      "\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_covtype\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_covtype\n",
      "\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kddcup99\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_kddcup99\n",
      "\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lfw\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_lfw_pairs, fetch_lfw_people\n",
      "\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_olivetti_faces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_olivetti_faces\n",
      "\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_openml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_openml\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\datasets\\_lfw.py:22\u001b[0m\n",
      "\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n",
      "\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hidden, Interval, StrOptions, validate_params\n",
      "\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tarfile_extractall\n",
      "\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[0;32m     24\u001b[0m     RemoteFileMetadata,\n",
      "\u001b[0;32m     25\u001b[0m     _fetch_remote,\n",
      "\u001b[0;32m     26\u001b[0m     get_data_home,\n",
      "\u001b[0;32m     27\u001b[0m     load_descr,\n",
      "\u001b[0;32m     28\u001b[0m )\n",
      "\u001b[0;32m     30\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'tarfile_extractall' from 'sklearn.utils.fixes' (c:\\Users\\GARV ANAND\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py)"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
